{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Лемматизация-и-подготовка-к-обучению\" data-toc-modified-id=\"Лемматизация-и-подготовка-к-обучению-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Лемматизация и подготовка к обучению</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>LGBMClassifier</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/datasets/toxic_comments.csv\")\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10167887648758234"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"toxic\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Данные не содержат пропусков и дубликатов.\n",
    "10.17% твитов в датасете являются токсичными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация и подготовка к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_clear(text):\n",
    "    cleaned = re.sub(r\"[^a-zA-Z\\' ]\", ' ', text)\n",
    "    return \" \".join(cleaned.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def ft_lemmatizer(text):\n",
    "    words_list = nltk.word_tokenize(text)\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in words_list])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lem_nltk'] = df['text'].apply(ft_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lem_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww He match this background colour I 'm see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I 'm really not trying to edit war It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer Umm there no actual article for prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And it look like it wa actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>And I really do n't think you understand I cam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                 lem_nltk  \n",
       "0       Explanation Why the edits made under my userna...  \n",
       "1       D'aww He match this background colour I 'm see...  \n",
       "2       Hey man I 'm really not trying to edit war It ...  \n",
       "3       More I ca n't make any real suggestion on impr...  \n",
       "4       You sir are my hero Any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566  And for the second time of asking when your vi...  \n",
       "159567  You should be ashamed of yourself That is a ho...  \n",
       "159568  Spitzer Umm there no actual article for prosti...  \n",
       "159569  And it look like it wa actually you who put on...  \n",
       "159570  And I really do n't think you understand I cam...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lem_nltk'] = df['lem_nltk'].apply(ft_lemmatizer)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook после этого падает\n",
    "#corpus = df['lem_nltk'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['lem_nltk'], target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (119678,)\n",
      "X_test: (39893,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119678, 138815)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf  = count_vect.fit_transform(X_train) \n",
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39893, 138815)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_test = count_vect.transform(X_test) \n",
    "tf_idf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке: 0.734\n",
      "CPU times: user 24 s, sys: 27.4 s, total: 51.5 s\n",
      "Wall time: 51.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(tf_idf, y_train)\n",
    "predicted = LR.predict(tf_idf_test)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print(f\"f1 на тестовой выборке: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=1, class_weight=balanced; total time=  49.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=1, class_weight=balanced; total time=  49.4s\n",
      "[CV] END .........................C=1, class_weight=balanced; total time=  29.9s\n",
      "[CV] END .............................C=1, class_weight=None; total time=  47.6s\n",
      "[CV] END .............................C=1, class_weight=None; total time=  47.7s\n",
      "[CV] END .............................C=1, class_weight=None; total time=  45.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=10, class_weight=balanced; total time=  46.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=10, class_weight=balanced; total time=  46.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=10, class_weight=balanced; total time=  46.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=10, class_weight=None; total time=  45.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=10, class_weight=None; total time=  46.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=10, class_weight=None; total time=  46.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=20, class_weight=balanced; total time=  44.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=20, class_weight=balanced; total time=  46.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=20, class_weight=balanced; total time=  46.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=20, class_weight=None; total time=  44.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=20, class_weight=None; total time=  46.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................C=20, class_weight=None; total time=  46.9s\n",
      "CPU times: user 6min 38s, sys: 7min 55s, total: 14min 33s\n",
      "Wall time: 14min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': [1, 10, 20], 'class_weight': ['balanced', None]},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "LR = LogisticRegression(random_state=42)\n",
    "params = {\"class_weight\": [\"balanced\", None], 'C':[1,10,20]}\n",
    "\n",
    "grid = GridSearchCV(LR, params,\n",
    "                  cv=3,\n",
    "                  scoring='f1',\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "grid.fit(tf_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid.best_score_ f1: 0.7574474369288406\n",
      "grid.best_params_ {'C': 10, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "print(\"grid.best_score_ f1:\", grid.best_score_)\n",
    "print(\"grid.best_params_\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке: 0.767\n"
     ]
    }
   ],
   "source": [
    "predicted = grid.predict(tf_idf_test)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print(f\"f1 на тестовой выборке: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке: 0.751\n",
      "CPU times: user 2min 44s, sys: 0 ns, total: 2min 44s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LGBM = LGBMClassifier(random_state=42)\n",
    "LGBM.fit(tf_idf, y_train)\n",
    "predicted = LGBM.predict(tf_idf_test)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print(f\"f1 на тестовой выборке: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12166, number of negative: 107512\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.997741\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.997741\n",
      "[LightGBM] [Debug] init for col-wise cost 32.804062 seconds, init for row-wise cost 33.513323 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 33.675579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 579093\n",
      "[LightGBM] [Info] Number of data points in the train set: 119678, number of used features: 10968\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101656 -> initscore=-2.178957\n",
      "[LightGBM] [Info] Start training from score -2.178957\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 24\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 29\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 27\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 30\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 28\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 26\n",
      "CPU times: user 2min 55s, sys: 0 ns, total: 2min 55s\n",
      "Wall time: 2min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(metric='f1', random_state=42, verbose=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "LGBM = LGBMClassifier(metric='f1', verbose=10, n_jobs=-1, random_state=42) \n",
    "LGBM.fit(tf_idf, y_train, eval_set=[(tf_idf_test, y_test)], eval_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке: 0.751\n"
     ]
    }
   ],
   "source": [
    "predicted = LGBM.predict(tf_idf_test)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print(f\"f1 на тестовой выборке: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END .....learning_rate=0.02, max_depth=6, num_leaves=50; total time= 1.1min\n",
      "[CV] END .....learning_rate=0.02, max_depth=6, num_leaves=50; total time=  51.2s\n",
      "[CV] END .....learning_rate=0.02, max_depth=6, num_leaves=50; total time=  50.9s\n",
      "[CV] END ....learning_rate=0.02, max_depth=6, num_leaves=100; total time=  52.1s\n",
      "[CV] END ....learning_rate=0.02, max_depth=6, num_leaves=100; total time=  50.0s\n",
      "[CV] END ....learning_rate=0.02, max_depth=6, num_leaves=100; total time=  50.5s\n",
      "[CV] END ....learning_rate=0.02, max_depth=12, num_leaves=50; total time= 1.4min\n",
      "[CV] END ....learning_rate=0.02, max_depth=12, num_leaves=50; total time= 1.4min\n",
      "[CV] END ....learning_rate=0.02, max_depth=12, num_leaves=50; total time= 1.4min\n",
      "[CV] END ...learning_rate=0.02, max_depth=12, num_leaves=100; total time= 1.7min\n",
      "[CV] END ...learning_rate=0.02, max_depth=12, num_leaves=100; total time= 1.7min\n",
      "[CV] END ...learning_rate=0.02, max_depth=12, num_leaves=100; total time= 1.7min\n",
      "[CV] END ......learning_rate=0.1, max_depth=6, num_leaves=50; total time=  46.4s\n",
      "[CV] END ......learning_rate=0.1, max_depth=6, num_leaves=50; total time=  47.1s\n",
      "[CV] END ......learning_rate=0.1, max_depth=6, num_leaves=50; total time=  49.1s\n",
      "[CV] END .....learning_rate=0.1, max_depth=6, num_leaves=100; total time=  48.0s\n",
      "[CV] END .....learning_rate=0.1, max_depth=6, num_leaves=100; total time=  49.4s\n",
      "[CV] END .....learning_rate=0.1, max_depth=6, num_leaves=100; total time= 1.0min\n",
      "[CV] END .....learning_rate=0.1, max_depth=12, num_leaves=50; total time= 1.5min\n",
      "[CV] END .....learning_rate=0.1, max_depth=12, num_leaves=50; total time= 1.7min\n",
      "[CV] END .....learning_rate=0.1, max_depth=12, num_leaves=50; total time= 1.9min\n",
      "[CV] END ....learning_rate=0.1, max_depth=12, num_leaves=100; total time= 2.0min\n",
      "[CV] END ....learning_rate=0.1, max_depth=12, num_leaves=100; total time= 1.6min\n",
      "[CV] END ....learning_rate=0.1, max_depth=12, num_leaves=100; total time= 1.5min\n",
      "CPU times: user 31min 38s, sys: 0 ns, total: 31min 38s\n",
      "Wall time: 31min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LGBMClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.02, 0.1], 'max_depth': [6, 12],\n",
       "                         'num_leaves': [50, 100]},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "LGBM = LGBMClassifier(random_state=42)\n",
    "params = {\n",
    "        'learning_rate':[0.02,0.1],\n",
    "        'num_leaves':[50, 100],\n",
    "        'max_depth': [6, 12]\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(LGBM, params,\n",
    "                  cv=3,\n",
    "                  scoring='f1',\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "grid.fit(tf_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid.best_score_ f1: 0.6921929974687394\n",
      "grid.best_params_ {'learning_rate': 0.1, 'max_depth': 12, 'num_leaves': 50}\n"
     ]
    }
   ],
   "source": [
    "print(\"grid.best_score_ f1:\", grid.best_score_)\n",
    "print(\"grid.best_params_\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке: 0.709\n"
     ]
    }
   ],
   "source": [
    "predicted = grid.predict(tf_idf_test)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print(f\"f1 на тестовой выборке: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе предобработки данных была произведена:\n",
    "- лемматизация и очистка текстов от стоп-слов при помощи инструментов библиотеки nltk\n",
    "- корпус текстов обработан и переведен в векторный вид при помощи TfidfVectorizer\n",
    "\n",
    "Лучший показатель F1 на тестовой выборки у модели LogisticRegression: 76.7%.\n",
    "\n",
    "У модели LGBMClassifier с параметрами по умолчанию показатель F1 так же удовлетворяет требованию: 75.1%.\n",
    "\n",
    "При этом и время обучения модели LogisticRegression быстрее LGBMClassifier: 14min 33s против 31min 45s\n",
    "\n",
    "Для задачи классификации комментариев на токсичность рекомендую применять модель  LogisticRegression."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 66903,
    "start_time": "2022-06-29T13:28:09.375Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T13:29:48.295Z"
   },
   {
    "duration": 672,
    "start_time": "2022-06-29T13:29:56.936Z"
   },
   {
    "duration": 49,
    "start_time": "2022-06-29T13:31:09.659Z"
   },
   {
    "duration": 2052,
    "start_time": "2022-06-29T13:31:41.812Z"
   },
   {
    "duration": 875,
    "start_time": "2022-06-29T13:32:24.580Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-29T13:32:41.094Z"
   },
   {
    "duration": 217,
    "start_time": "2022-06-29T13:35:54.864Z"
   },
   {
    "duration": 194,
    "start_time": "2022-06-29T13:36:01.199Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-29T13:54:49.295Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-29T13:54:58.839Z"
   },
   {
    "duration": 1069275,
    "start_time": "2022-06-29T13:56:01.457Z"
   },
   {
    "duration": 2139,
    "start_time": "2022-06-29T14:14:05.119Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-29T14:15:40.656Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-29T14:15:52.493Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T14:17:14.170Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-29T14:19:18.925Z"
   },
   {
    "duration": 5704,
    "start_time": "2022-06-29T14:26:01.135Z"
   },
   {
    "duration": 128699,
    "start_time": "2022-06-29T14:26:17.472Z"
   },
   {
    "duration": 2216,
    "start_time": "2022-06-29T14:28:33.324Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-29T14:28:51.265Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-29T14:44:36.110Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-29T14:47:14.773Z"
   },
   {
    "duration": 49916,
    "start_time": "2022-06-30T03:45:40.589Z"
   },
   {
    "duration": 448,
    "start_time": "2022-06-30T03:46:30.507Z"
   },
   {
    "duration": 2215,
    "start_time": "2022-06-30T03:46:30.957Z"
   },
   {
    "duration": 226,
    "start_time": "2022-06-30T03:46:33.174Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T03:46:33.402Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T03:46:33.408Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-30T03:46:33.427Z"
   },
   {
    "duration": 1103,
    "start_time": "2022-06-30T03:46:33.431Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T03:46:34.536Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T03:46:34.538Z"
   },
   {
    "duration": 1,
    "start_time": "2022-06-30T03:46:34.539Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T03:46:34.541Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T03:46:34.542Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T03:46:34.544Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T03:46:34.545Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-30T03:52:16.684Z"
   },
   {
    "duration": 1964,
    "start_time": "2022-06-30T03:53:11.662Z"
   },
   {
    "duration": 80190,
    "start_time": "2022-06-30T03:53:26.630Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T03:58:25.828Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T03:59:31.823Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T04:00:09.040Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T04:00:59.292Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T04:01:11.715Z"
   },
   {
    "duration": 132686,
    "start_time": "2022-06-30T04:02:28.765Z"
   },
   {
    "duration": 2072,
    "start_time": "2022-06-30T04:04:48.202Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-30T04:04:56.851Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T04:04:59.652Z"
   },
   {
    "duration": 46592,
    "start_time": "2022-06-30T04:07:50.180Z"
   },
   {
    "duration": 196,
    "start_time": "2022-06-30T04:08:36.774Z"
   },
   {
    "duration": 847,
    "start_time": "2022-06-30T04:08:36.972Z"
   },
   {
    "duration": 227,
    "start_time": "2022-06-30T04:08:37.821Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T04:08:38.049Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T04:08:38.055Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T04:08:38.062Z"
   },
   {
    "duration": 2069,
    "start_time": "2022-06-30T04:08:38.069Z"
   },
   {
    "duration": 81473,
    "start_time": "2022-06-30T04:08:40.140Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-30T04:10:01.616Z"
   },
   {
    "duration": 325,
    "start_time": "2022-06-30T04:10:01.628Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:10:01.955Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:10:01.956Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:10:01.958Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:10:01.959Z"
   },
   {
    "duration": 774,
    "start_time": "2022-06-30T04:43:13.664Z"
   },
   {
    "duration": 47,
    "start_time": "2022-06-30T04:44:13.075Z"
   },
   {
    "duration": 48148,
    "start_time": "2022-06-30T04:44:44.934Z"
   },
   {
    "duration": 359,
    "start_time": "2022-06-30T04:45:33.083Z"
   },
   {
    "duration": 2096,
    "start_time": "2022-06-30T04:45:33.444Z"
   },
   {
    "duration": 225,
    "start_time": "2022-06-30T04:45:35.541Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T04:45:35.768Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-30T04:45:35.774Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-30T04:45:35.783Z"
   },
   {
    "duration": 1995,
    "start_time": "2022-06-30T04:45:35.792Z"
   },
   {
    "duration": 77323,
    "start_time": "2022-06-30T04:45:37.789Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T04:46:55.114Z"
   },
   {
    "duration": 48,
    "start_time": "2022-06-30T04:47:22.787Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-30T04:47:46.828Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-30T04:50:03.458Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-30T04:52:24.775Z"
   },
   {
    "duration": 47648,
    "start_time": "2022-06-30T04:52:29.604Z"
   },
   {
    "duration": 284,
    "start_time": "2022-06-30T04:53:17.255Z"
   },
   {
    "duration": 2140,
    "start_time": "2022-06-30T04:53:17.540Z"
   },
   {
    "duration": 219,
    "start_time": "2022-06-30T04:53:19.681Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T04:53:19.902Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-30T04:53:19.908Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-30T04:53:19.930Z"
   },
   {
    "duration": 2023,
    "start_time": "2022-06-30T04:53:19.935Z"
   },
   {
    "duration": 84760,
    "start_time": "2022-06-30T04:53:21.960Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-30T04:54:46.723Z"
   },
   {
    "duration": 356,
    "start_time": "2022-06-30T04:54:46.735Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:54:47.093Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:54:47.094Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:54:47.096Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:54:47.097Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:54:47.099Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T04:54:47.100Z"
   },
   {
    "duration": 1935,
    "start_time": "2022-06-30T04:55:02.289Z"
   },
   {
    "duration": 52429,
    "start_time": "2022-06-30T04:56:32.995Z"
   },
   {
    "duration": 299,
    "start_time": "2022-06-30T04:57:25.428Z"
   },
   {
    "duration": 2418,
    "start_time": "2022-06-30T04:57:25.729Z"
   },
   {
    "duration": 243,
    "start_time": "2022-06-30T04:57:28.149Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T04:57:28.394Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T04:57:28.400Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-30T04:57:28.406Z"
   },
   {
    "duration": 2066,
    "start_time": "2022-06-30T04:57:28.442Z"
   },
   {
    "duration": 87653,
    "start_time": "2022-06-30T04:57:30.510Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T04:58:58.165Z"
   },
   {
    "duration": 2016,
    "start_time": "2022-06-30T04:58:58.171Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-30T04:59:00.190Z"
   },
   {
    "duration": 57158,
    "start_time": "2022-06-30T05:00:00.798Z"
   },
   {
    "duration": 360,
    "start_time": "2022-06-30T05:00:57.959Z"
   },
   {
    "duration": 2430,
    "start_time": "2022-06-30T05:00:58.321Z"
   },
   {
    "duration": 239,
    "start_time": "2022-06-30T05:01:00.754Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T05:01:00.995Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-30T05:01:01.001Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-30T05:01:01.010Z"
   },
   {
    "duration": 2136,
    "start_time": "2022-06-30T05:01:01.035Z"
   },
   {
    "duration": 85706,
    "start_time": "2022-06-30T05:01:03.173Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T05:02:28.881Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-30T05:02:28.887Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-30T05:02:28.894Z"
   },
   {
    "duration": 50,
    "start_time": "2022-06-30T05:02:28.904Z"
   },
   {
    "duration": 360,
    "start_time": "2022-06-30T05:02:28.956Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T05:02:29.317Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T05:02:29.319Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T05:02:29.320Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-30T05:05:47.878Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-30T05:06:05.653Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T05:06:52.694Z"
   },
   {
    "duration": 48,
    "start_time": "2022-06-30T05:09:53.397Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T05:10:23.208Z"
   },
   {
    "duration": 5486,
    "start_time": "2022-06-30T05:10:49.758Z"
   },
   {
    "duration": 5633,
    "start_time": "2022-06-30T05:11:43.057Z"
   },
   {
    "duration": 1537,
    "start_time": "2022-06-30T05:20:58.215Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-30T05:25:00.938Z"
   },
   {
    "duration": 22,
    "start_time": "2022-06-30T05:25:11.266Z"
   },
   {
    "duration": 281262,
    "start_time": "2022-06-30T05:27:59.220Z"
   },
   {
    "duration": 320727,
    "start_time": "2022-06-30T05:37:51.506Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T05:43:19.186Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T05:47:51.821Z"
   },
   {
    "duration": 52,
    "start_time": "2022-06-30T05:50:07.266Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-30T05:51:03.700Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-30T05:51:17.513Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-30T05:52:39.659Z"
   },
   {
    "duration": 30,
    "start_time": "2022-06-30T05:52:40.518Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-30T05:52:44.664Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-30T05:58:50.551Z"
   },
   {
    "duration": 943802,
    "start_time": "2022-06-30T06:02:40.873Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T06:20:56.313Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T06:21:28.420Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-30T06:23:22.762Z"
   },
   {
    "duration": 65,
    "start_time": "2022-06-30T06:23:35.458Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-30T06:23:38.209Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-30T06:23:45.050Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-30T06:25:24.694Z"
   },
   {
    "duration": 26,
    "start_time": "2022-06-30T06:26:55.052Z"
   },
   {
    "duration": 25,
    "start_time": "2022-06-30T06:27:02.141Z"
   },
   {
    "duration": 144,
    "start_time": "2022-06-30T06:27:43.067Z"
   },
   {
    "duration": 2925264,
    "start_time": "2022-06-30T06:28:36.773Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T07:18:03.189Z"
   },
   {
    "duration": 1607,
    "start_time": "2022-06-30T07:18:07.532Z"
   },
   {
    "duration": 56480,
    "start_time": "2022-06-30T07:20:22.908Z"
   },
   {
    "duration": 395,
    "start_time": "2022-06-30T07:21:19.390Z"
   },
   {
    "duration": 816,
    "start_time": "2022-06-30T07:21:19.787Z"
   },
   {
    "duration": 228,
    "start_time": "2022-06-30T07:21:20.605Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-30T07:21:20.835Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-30T07:21:20.841Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-30T07:21:20.861Z"
   },
   {
    "duration": 1893,
    "start_time": "2022-06-30T07:21:20.881Z"
   },
   {
    "duration": 77029,
    "start_time": "2022-06-30T07:21:22.775Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T07:22:39.806Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-30T07:22:39.812Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-30T07:22:39.828Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-30T07:22:39.833Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-30T07:22:39.869Z"
   },
   {
    "duration": 4898,
    "start_time": "2022-06-30T07:22:39.874Z"
   },
   {
    "duration": 1690,
    "start_time": "2022-06-30T07:22:44.776Z"
   },
   {
    "duration": 330413,
    "start_time": "2022-06-30T07:22:46.468Z"
   },
   {
    "duration": 1,
    "start_time": "2022-06-30T07:28:16.883Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T07:28:16.885Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T07:28:16.886Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-30T07:28:16.887Z"
   },
   {
    "duration": 1,
    "start_time": "2022-06-30T07:28:16.888Z"
   },
   {
    "duration": 51704,
    "start_time": "2022-06-30T07:29:33.543Z"
   },
   {
    "duration": 205168,
    "start_time": "2022-06-30T07:31:47.083Z"
   },
   {
    "duration": 76,
    "start_time": "2022-06-30T07:37:27.369Z"
   },
   {
    "duration": 75,
    "start_time": "2022-06-30T07:37:59.323Z"
   },
   {
    "duration": 91,
    "start_time": "2022-06-30T07:38:06.868Z"
   },
   {
    "duration": 183860,
    "start_time": "2022-06-30T07:38:15.451Z"
   },
   {
    "duration": 39,
    "start_time": "2022-06-30T07:41:41.509Z"
   },
   {
    "duration": 3099,
    "start_time": "2022-06-30T07:41:53.886Z"
   },
   {
    "duration": 3107,
    "start_time": "2022-06-30T07:42:26.151Z"
   },
   {
    "duration": 66343,
    "start_time": "2022-06-30T07:44:57.043Z"
   },
   {
    "duration": 218,
    "start_time": "2022-06-30T07:46:03.388Z"
   },
   {
    "duration": 964,
    "start_time": "2022-06-30T07:46:03.608Z"
   },
   {
    "duration": 263,
    "start_time": "2022-06-30T07:46:04.575Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-30T07:46:04.847Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-30T07:46:04.858Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-30T07:46:04.872Z"
   },
   {
    "duration": 2359,
    "start_time": "2022-06-30T07:46:04.880Z"
   },
   {
    "duration": 91106,
    "start_time": "2022-06-30T07:46:07.245Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T07:47:38.354Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-30T07:47:38.360Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-30T07:47:38.366Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-30T07:47:38.379Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-30T07:47:38.425Z"
   },
   {
    "duration": 5692,
    "start_time": "2022-06-30T07:47:38.440Z"
   },
   {
    "duration": 1822,
    "start_time": "2022-06-30T07:47:44.135Z"
   },
   {
    "duration": 51514,
    "start_time": "2022-06-30T07:47:45.959Z"
   },
   {
    "duration": 874904,
    "start_time": "2022-06-30T07:48:37.527Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-30T08:03:12.433Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-30T08:03:12.438Z"
   },
   {
    "duration": 165271,
    "start_time": "2022-06-30T08:03:12.477Z"
   },
   {
    "duration": 176299,
    "start_time": "2022-06-30T08:05:57.750Z"
   },
   {
    "duration": 3517,
    "start_time": "2022-06-30T08:08:54.051Z"
   },
   {
    "duration": 1905392,
    "start_time": "2022-06-30T08:08:57.570Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-30T08:40:42.964Z"
   },
   {
    "duration": 1565,
    "start_time": "2022-06-30T08:40:42.968Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
